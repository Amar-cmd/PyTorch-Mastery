{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8aee4be-9096-4afb-af0e-ed5a5495e753",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/PyTorch_logo_black.svg/1280px-PyTorch_logo_black.svg.png' width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cc07a-2341-4969-94dc-82400920695d",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319b9e6-6dba-4d2b-bf4b-7673e1603e36",
   "metadata": {},
   "source": [
    "<img src='https://saturncloud.io/images/blog/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way.webp'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011760a-9b68-4c8d-99b6-edf50f1903a0",
   "metadata": {},
   "source": [
    "CNN in machine learning stands for Convolutional Neural Network, a class of deep neural networks, most commonly applied to analyzing visual imagery. \n",
    "\n",
    "###  Key Components of CNNs:\n",
    "- **Convolutional Layers**: These layers perform a convolution operation, filtering the input data to extract features. They use learnable kernels (or filters) to capture spatial hierarchies in images, such as edges in the early layers, and more complex patterns (like textures or specific objects) in deeper layers.\n",
    "\n",
    "- **ReLU (Rectified Linear Unit) Layer:** This layer applies a non-linear activation function, like ReLU, which introduces non-linearity to the model, allowing it to learn complex patterns. ReLU is commonly used because it helps with the vanishing gradient problem and speeds up training.\n",
    "\n",
    "- **Pooling (Subsampling or Down-sampling) Layers:** Pooling reduces the spatial size of the representation, reducing the number of parameters and computation in the network, and hence controlling overfitting. Max pooling (taking the maximum value from a set of values) is the most common pooling method.\n",
    "\n",
    "- **Fully Connected Layers:** Towards the end, CNNs have one or more fully connected layers (similar to those in traditional neural networks) where all neurons in previous layers are connected to each neuron in the fully connected layer. These layers are used to classify the images into labels based on the high-level features identified in the convolutional and pooling layers.\n",
    "\n",
    "- **Softmax Layer:** In classification tasks, the softmax layer is often used as the last layer of a CNN to normalize the output into a probability distribution over predicted output classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee6e19-9d2a-49ab-9cd0-84367b8caad4",
   "metadata": {},
   "source": [
    "### CNN Architecture\n",
    "1. **Input Layer**\n",
    "- **Purpose:** Accepts the raw pixel values of the image.\n",
    "- **Details:** The dimensions of the input layer correspond to the dimensions of the input image (height, width, channels), where channels represent color depths (e.g., 3 for RGB images).\n",
    "2. **Convolutional Layer**\n",
    "- **Purpose:** Extracts features from the input image.\n",
    "- **Details:** Utilizes learnable kernels or filters to perform the convolution operation, producing feature maps. This layer is key to learning image features.\n",
    "3. **Activation Layer (ReLU)**\n",
    "- **Purpose:** Introduces non-linearity into the model, allowing it to learn more complex patterns.\n",
    "- **Details:** The Rectified Linear Unit (ReLU) is the most commonly used activation function in CNNs, converting all negative values in the feature maps to zero and keeping positive values unchanged.\n",
    "4. **Pooling Layer**\n",
    "- **Purpose:** Reduces the spatial dimensions (width and height) of the input volume for the next convolutional layer, reducing the number of parameters and computation in the network.\n",
    "- **Details:** Max pooling is the most common technique, which reduces the input size by taking the maximum value over a spatial window.\n",
    "5. **Fully Connected (FC) Layer**\n",
    "- **Purpose:** Performs high-level reasoning like classifying the features learned by the CNN.\n",
    "- **Details:** Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. The last fully connected layer outputs the final predictions.\n",
    "6. **Softmax or Logistic Layer**\n",
    "- **Purpose:** Generates a probability distribution over classes for classification tasks.\n",
    "- **Details:** The softmax function is typically used in the final layer of a classifier, converting the output scores from the final fully connected layer into probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42881e5b-86fd-45d6-a1f3-58fb6dc619ea",
   "metadata": {},
   "source": [
    "# Torchvision\n",
    "### Dataset\n",
    "- All datasets are subclasses of **`torch.utils.data.Dataset`** i.e, they have `__getitem__` and `__len__` methods implemented. Hence, they can all be passed to a **`torch.utils.data.DataLoader`** which can load multiple samples in parallel using torch.multiprocessing workers.\n",
    "- Image Classification Datasets includes:\n",
    "    -  MNIST Dataset\n",
    "    -  Fashion-MNIST\n",
    "    -  EMNIST\n",
    "    -  KMNIST\n",
    "    -  QMNIST\n",
    "    -  CIFAR10\n",
    "    -  CIFAR100\n",
    " \n",
    "### Transform\n",
    "- A crucial part of the data preprocessing pipeline in PyTorch.\n",
    "- Perform image transformations that help in augmenting and normalizing datasets for training neural networks.\n",
    "> **Data augmentation** refers to the process of generating new training samples from the original dataset by applying various transformations like *rotation, flipping, scaling, or cropping*, to *increase the diversity of data* without actually collecting new data.\n",
    "1. __Purpose__: Data Augmentation to improve the robustness and performance of neural network models.\n",
    "2. __Types of Transforms__:\n",
    "    - __Basic Transforms__: Operations like __Resize, CenterCrop, ToTensor, and Normalize__ are fundamental for adjusting the dimensions of images and converting them into tensor format with normalized values.\n",
    "    - __Augmentation Transforms__: Includes operations like __RandomCrop, RandomHorizontalFlip, RandomRotation__, etc., which introduce randomness in the dataset to prevent overfitting and improve model generalization.\n",
    "3. **Composing Transforms**: Transforms can be composed using `torchvision.transforms.Compose`, allowing multiple transformations to be applied sequentially.\n",
    "4. __Normalization__: Normalization, using the Normalize transform, adjusts pixel intensity values. Itâ€™s crucial for models to converge faster.\n",
    "5. **Tensor Conversion**: The '**ToTensor**' transform converts PIL images or NumPy arrays into PyTorch tensors, changing the image's pixel value range from 0-255 to 0-1. This is a necessary step before applying normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbf1cb-cb56-4581-86f3-d47828d7c30f",
   "metadata": {},
   "source": [
    "## Getting Training and Testing Data from Torchvision Datasets \n",
    "\n",
    "```\n",
    "train_data = datasets.FashionMNIST(\r\n",
    "    root='data',                # Specifies the directory where the dataset will be stored or loaded from.\r\n",
    "    train=True,                 # Indicates that the dataset being loaded is for training purpos *False* in case of Test datasetes.\r\n",
    "    download=True,              # If the dataset is not available in the 'root' directory, download it.\r\n",
    "    transform=ToTensor(),       # Applies a transformation to convert image data into a tensor.\r\n",
    "    target_transform=None       # No transformation is applied to the labels of the data```set.\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac1cdf-4a79-4dfc-b1b9-d04b861bd687",
   "metadata": {},
   "source": [
    "### NOTE: This dataset returns a Tuple of (image, target) where target is index of the target class. It can be accessed using instance classes or instance class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9a0b2-d6b3-42d8-b222-665574f8dc65",
   "metadata": {},
   "source": [
    "## Vizualizatoin of Dataset as Image\n",
    "- Matplotlib's imshow is used. It display data as an image, i.e., on a 2D regular raster.\n",
    "- imshow accept only (m,n) dimension.\n",
    "- Default Dataset dimension is (channel, width, height => 1,28,28).\n",
    "- Use squeeze to remove extra dimension, 1 in this case, to use imshow to display data as image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a8f68-b638-4a88-99b3-4c41b0aa46d5",
   "metadata": {},
   "source": [
    "## Torchvision DataLoader\n",
    "* **Purpose:**\n",
    "The DataLoader wraps a dataset and provides an iterable over the dataset, allowing for easy access to batches of data. This is crucial for training models on large datasets efficiently.\n",
    "---\n",
    "* **Batch Loading:**\n",
    "It supports automatic batching of data, meaning it groups the dataset into smaller, manageable batches of data that are fed into the neural network during training. This helps in optimizing the training process and managing memory usage.\n",
    "---\n",
    "* **Shuffling:**\n",
    "The DataLoader can shuffle the data at the beginning of each epoch, preventing the model from learning the order of the data and helping it generalize better.\n",
    "***\n",
    "* **Parallel Data Loading:**\n",
    "With the **num_workers** parameter, it allows for parallel data loading using multiple subprocesses. This significantly speeds up data preprocessing and reduces the time to train a model, especially on large datasets.\n",
    "---\n",
    "* **Handling of Last Incomplete Batch:**\n",
    "The drop_last parameter determines whether to include the last batch in the iteration when its size is smaller than the specified batch size, giving control over handling of dataset size not divisible by the batch size.\n",
    "---\n",
    "* **Iterable and Lazy Loading:**\n",
    "The DataLoader provides an iterable over the dataset, enabling lazy loading of data. This means data is loaded and transformed on-the-fly as needed during training, rather than all at once, which is memory efficient.\n",
    "\n",
    "### How to use?\n",
    "```python\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize the DataLoader for the training data\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ff18d-dd22-4a39-8a7e-04ab434031be",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "- Three fundamental componentsâ€”`Conv2d`, `ReLU`, and `MaxPool2d`\n",
    "---\n",
    "## Conv2d (Convolutional Layer)\n",
    "- **Purpose**: The **\"Conv2d\"** layer performs a 2-dimensional convolution operation. It is the core building block of CNNs, used to extract features from input images through learnable filters (kernels).\n",
    "- **Parameters**:\n",
    "    - **in_channels**: Number of channels in the input image (e.g., 3 for RGB images).\n",
    "    - **out_channels**: Number of filters used in the convolution. This also represents the number of feature maps\n",
    "    - **generatedkernel_size**: Size of the convolving kernel. It can be a single number or a tuple (height, width) representing the height and width of the kernel.\n",
    "    - **stride**: Control the step size of the kernel as it moves across the image. A larger stride reduces the spatial dimensions of the output.\n",
    "    - **padding**: Adds zero-padding to the input on all sides to control the spatial size of the output.\n",
    "- **Functionality**: It applies a convolution operation that helps in detecting specific features like edges, textures, or complex patterns in the input image, depending on the learnability of the filters during training.\n",
    "---\n",
    "## ReLU (Rectified Linear Unit)\n",
    "- **Purpose**: ReLU is a non-linear activation function used to introduce non-linearity into the CNN, allowing it to learn complex patterns.\n",
    "- **Functionality**: It transforms the input by replacing all negative values in the feature maps with zero **(f(x) = max(0, x))**. This simple operation helps in speeding up the training process and improving the network's ability to learn complex patterns without significantly increasing computational cost.\n",
    "---\n",
    "## MaxPool2d (Max Pooling Layer)\n",
    "\n",
    "- **Purpose**: The MaxPool2d layer performs a downsampling operation, reducing the spatial dimensions (width and height) of the input feature maps, leading to a reduction in the computational load for subsequent layers and overfitting by providing an abstracted form of the features.\n",
    "- **Parameters**:\n",
    "    - **kernel_size**: The size of the window over which to take the maximum. It determines how much the input dimensions are reduced.\n",
    "    - **stride**: Controls the step size of the pooling operation. Often, the stride is set equal to the kernel size to avoid overlap.\n",
    "    - **padding**: Sometimes used to add zeros around the borders of the input before applying the max pooling operation.\n",
    "- **Functionality**: It operates on each feature map independently, selecting the maximum value within the region defined by the kernel size. This helps in extracting the most prominent features and achieving spatial invariance to input variations.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d703b4-d8e5-478e-aa09-76013e444781",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "```python\n",
    "self.block_1 = nn.Sequential(\r\n",
    "    nn.Conv2d(in_channels=input_shape, # Number of input channels (depth of input image)\r\n",
    "              out_channels=hidden_units, # Number of output channels (filters)\r\n",
    "              kernel_size=3, # Size of the convolutional kernel (3x3 square)\r\n",
    "              stride=1, # Stride of the convolution (1 pixel at a time)\r\n",
    "              padding=1),# Padding applied to input (1 pixel on all sides for maintaining input size)\r\n",
    "    nn.ReLU(), # Applies the ReLU activation function\r\n",
    "    nn.Conv2d(in_channels=hidden_units, # Number of input channels, matches previous layer's output\r\n",
    "              out_channels=hidden_units, # Number of output channels, same as previous to maintain depth\r\n",
    "              kernel_size=3, # Size of the convolutional kernel (3x3 square)\r\n",
    "              stride=1, # Stride of the convolution (1 pixel at a time)\r\n",
    "              padding=1), # Padding applied to input (1 pixel on all sides for maintaining input size)\r\n",
    "    nn.ReLU(), # Applies the ReLU activation function again\r\n",
    "    nn.MaxPool2d(kernel_size=2, # Size of the max pooling window (2x2 square)\r\n",
    "                 stride=2) # Stride for max pooling (2 pixels at a time, reduces size by half)\r\n",
    ")\r\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
