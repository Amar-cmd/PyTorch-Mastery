{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682a92dc",
   "metadata": {},
   "source": [
    "![title](https://meterpreter.org/wp-content/uploads/2017/12/pytorch-logo-dark-1024x205.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a266d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3cc90e",
   "metadata": {},
   "source": [
    "# 1. Checking for GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b405f81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91461ec",
   "metadata": {},
   "source": [
    "# 2. Number of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7920c7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67991b2d",
   "metadata": {},
   "source": [
    "# 3. Setting Up Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40058700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tensor = torch.tensor([1,2,3])\n",
    "# Move Tensors to GPU\n",
    "tensor = tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850886cc",
   "metadata": {},
   "source": [
    "# 4. CUDA Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1bfb8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.8'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb9cbf",
   "metadata": {},
   "source": [
    "# 5. GPU Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5063684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650 Ti\n",
      "(7, 5)\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1650 Ti', major=7, minor=5, total_memory=4095MB, multi_processor_count=16)\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "    print(torch.cuda.get_device_capability(i))\n",
    "    print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a7816de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  3 22:33:26 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.17                 Driver Version: 546.17       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   34C    P8               1W /  50W |     54MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     16176      C   C:\\Python311\\python.exe                   N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90f605d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5d072b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\torch\\cuda\\memory.py:444: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2097152"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1556a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097152"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ba204e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('active.all.allocated', 1),\n",
       "             ('active.all.current', 1),\n",
       "             ('active.all.freed', 0),\n",
       "             ('active.all.peak', 1),\n",
       "             ('active.large_pool.allocated', 0),\n",
       "             ('active.large_pool.current', 0),\n",
       "             ('active.large_pool.freed', 0),\n",
       "             ('active.large_pool.peak', 0),\n",
       "             ('active.small_pool.allocated', 1),\n",
       "             ('active.small_pool.current', 1),\n",
       "             ('active.small_pool.freed', 0),\n",
       "             ('active.small_pool.peak', 1),\n",
       "             ('active_bytes.all.allocated', 512),\n",
       "             ('active_bytes.all.current', 512),\n",
       "             ('active_bytes.all.freed', 0),\n",
       "             ('active_bytes.all.peak', 512),\n",
       "             ('active_bytes.large_pool.allocated', 0),\n",
       "             ('active_bytes.large_pool.current', 0),\n",
       "             ('active_bytes.large_pool.freed', 0),\n",
       "             ('active_bytes.large_pool.peak', 0),\n",
       "             ('active_bytes.small_pool.allocated', 512),\n",
       "             ('active_bytes.small_pool.current', 512),\n",
       "             ('active_bytes.small_pool.freed', 0),\n",
       "             ('active_bytes.small_pool.peak', 512),\n",
       "             ('allocated_bytes.all.allocated', 512),\n",
       "             ('allocated_bytes.all.current', 512),\n",
       "             ('allocated_bytes.all.freed', 0),\n",
       "             ('allocated_bytes.all.peak', 512),\n",
       "             ('allocated_bytes.large_pool.allocated', 0),\n",
       "             ('allocated_bytes.large_pool.current', 0),\n",
       "             ('allocated_bytes.large_pool.freed', 0),\n",
       "             ('allocated_bytes.large_pool.peak', 0),\n",
       "             ('allocated_bytes.small_pool.allocated', 512),\n",
       "             ('allocated_bytes.small_pool.current', 512),\n",
       "             ('allocated_bytes.small_pool.freed', 0),\n",
       "             ('allocated_bytes.small_pool.peak', 512),\n",
       "             ('allocation.all.allocated', 1),\n",
       "             ('allocation.all.current', 1),\n",
       "             ('allocation.all.freed', 0),\n",
       "             ('allocation.all.peak', 1),\n",
       "             ('allocation.large_pool.allocated', 0),\n",
       "             ('allocation.large_pool.current', 0),\n",
       "             ('allocation.large_pool.freed', 0),\n",
       "             ('allocation.large_pool.peak', 0),\n",
       "             ('allocation.small_pool.allocated', 1),\n",
       "             ('allocation.small_pool.current', 1),\n",
       "             ('allocation.small_pool.freed', 0),\n",
       "             ('allocation.small_pool.peak', 1),\n",
       "             ('inactive_split.all.allocated', 1),\n",
       "             ('inactive_split.all.current', 1),\n",
       "             ('inactive_split.all.freed', 0),\n",
       "             ('inactive_split.all.peak', 1),\n",
       "             ('inactive_split.large_pool.allocated', 0),\n",
       "             ('inactive_split.large_pool.current', 0),\n",
       "             ('inactive_split.large_pool.freed', 0),\n",
       "             ('inactive_split.large_pool.peak', 0),\n",
       "             ('inactive_split.small_pool.allocated', 1),\n",
       "             ('inactive_split.small_pool.current', 1),\n",
       "             ('inactive_split.small_pool.freed', 0),\n",
       "             ('inactive_split.small_pool.peak', 1),\n",
       "             ('inactive_split_bytes.all.allocated', 2096640),\n",
       "             ('inactive_split_bytes.all.current', 2096640),\n",
       "             ('inactive_split_bytes.all.freed', 0),\n",
       "             ('inactive_split_bytes.all.peak', 2096640),\n",
       "             ('inactive_split_bytes.large_pool.allocated', 0),\n",
       "             ('inactive_split_bytes.large_pool.current', 0),\n",
       "             ('inactive_split_bytes.large_pool.freed', 0),\n",
       "             ('inactive_split_bytes.large_pool.peak', 0),\n",
       "             ('inactive_split_bytes.small_pool.allocated', 2096640),\n",
       "             ('inactive_split_bytes.small_pool.current', 2096640),\n",
       "             ('inactive_split_bytes.small_pool.freed', 0),\n",
       "             ('inactive_split_bytes.small_pool.peak', 2096640),\n",
       "             ('max_split_size', -1),\n",
       "             ('num_alloc_retries', 0),\n",
       "             ('num_ooms', 0),\n",
       "             ('oversize_allocations.allocated', 0),\n",
       "             ('oversize_allocations.current', 0),\n",
       "             ('oversize_allocations.freed', 0),\n",
       "             ('oversize_allocations.peak', 0),\n",
       "             ('oversize_segments.allocated', 0),\n",
       "             ('oversize_segments.current', 0),\n",
       "             ('oversize_segments.freed', 0),\n",
       "             ('oversize_segments.peak', 0),\n",
       "             ('requested_bytes.all.allocated', 24),\n",
       "             ('requested_bytes.all.current', 24),\n",
       "             ('requested_bytes.all.freed', 0),\n",
       "             ('requested_bytes.all.peak', 24),\n",
       "             ('requested_bytes.large_pool.allocated', 0),\n",
       "             ('requested_bytes.large_pool.current', 0),\n",
       "             ('requested_bytes.large_pool.freed', 0),\n",
       "             ('requested_bytes.large_pool.peak', 0),\n",
       "             ('requested_bytes.small_pool.allocated', 24),\n",
       "             ('requested_bytes.small_pool.current', 24),\n",
       "             ('requested_bytes.small_pool.freed', 0),\n",
       "             ('requested_bytes.small_pool.peak', 24),\n",
       "             ('reserved_bytes.all.allocated', 2097152),\n",
       "             ('reserved_bytes.all.current', 2097152),\n",
       "             ('reserved_bytes.all.freed', 0),\n",
       "             ('reserved_bytes.all.peak', 2097152),\n",
       "             ('reserved_bytes.large_pool.allocated', 0),\n",
       "             ('reserved_bytes.large_pool.current', 0),\n",
       "             ('reserved_bytes.large_pool.freed', 0),\n",
       "             ('reserved_bytes.large_pool.peak', 0),\n",
       "             ('reserved_bytes.small_pool.allocated', 2097152),\n",
       "             ('reserved_bytes.small_pool.current', 2097152),\n",
       "             ('reserved_bytes.small_pool.freed', 0),\n",
       "             ('reserved_bytes.small_pool.peak', 2097152),\n",
       "             ('segment.all.allocated', 1),\n",
       "             ('segment.all.current', 1),\n",
       "             ('segment.all.freed', 0),\n",
       "             ('segment.all.peak', 1),\n",
       "             ('segment.large_pool.allocated', 0),\n",
       "             ('segment.large_pool.current', 0),\n",
       "             ('segment.large_pool.freed', 0),\n",
       "             ('segment.large_pool.peak', 0),\n",
       "             ('segment.small_pool.allocated', 1),\n",
       "             ('segment.small_pool.current', 1),\n",
       "             ('segment.small_pool.freed', 0),\n",
       "             ('segment.small_pool.peak', 1)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ac76d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    512 B   |    512 B   |    512 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |    512 B   |    512 B   |    512 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    512 B   |    512 B   |    512 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |    512 B   |    512 B   |    512 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |     24 B   |     24 B   |     24 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |     24 B   |     24 B   |     24 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |\n",
      "|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 B   |\n",
      "|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   2047 KiB |   2047 KiB |   2047 KiB |      0 B   |\n",
      "|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 B   |\n",
      "|       from small pool |   2047 KiB |   2047 KiB |   2047 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
